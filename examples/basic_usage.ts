/**
 * Basic Usage Example for Rust-AV Kit
 *
 * This example demonstrates basic usage of the Rust-AV Kit library
 * for media transcoding, format transformation, and media info extraction.
 *
 * Note: This example uses test videos generated by FFmpeg.
 * Run `bun run videos:fetch` to generate sample videos first.
 */

import {
  getMediaInfo,
  transcode,
  transformFormat,
  getSupportedFormats,
  getSupportedCodecs,
  getSupportedPixelFormats,
  getSupportedSampleFormats,
  validateFile,
  extractFramesAsRgba,
  saveFramesAsImages,
  extractFramesToImages,
  extractFramesWithVFrame,
} from '../index.js';

import * as fs from 'node:fs';
import * as path from 'node:path';

// ============================================================================
// Helper Functions
// ============================================================================

/**
 * Get a test video file path
 * Throws error if video doesn't exist
 */
function getTestVideo(filename: string): string {
  const filePath = path.join(__dirname, 'test_files', filename);
  if (fs.existsSync(filePath)) {
    return filePath;
  }
  
  throw new Error(
    `Test video not found: ${filename}. Run 'bun run videos:fetch' to generate sample videos.`
  );
}

// ============================================================================
// Example 1: Get Supported Formats and Codecs
// ============================================================================

console.log('=== Example 1: Get Supported Formats and Codecs ===\n');

const formats = getSupportedFormats();
console.log('Supported formats:', formats);

const codecs = getSupportedCodecs();
console.log('Supported codecs:', codecs);

const pixelFormats = getSupportedPixelFormats();
console.log('Supported pixel formats:', pixelFormats);

const sampleFormats = getSupportedSampleFormats();
console.log('Supported sample formats:', sampleFormats);

// ============================================================================
// Example 2: Get Media Information
// ============================================================================

console.log('\n=== Example 2: Get Media Information ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath = getTestVideo('sample_320x240.y4m');

// Get media information from file
try {
  const mediaInfo = getMediaInfo(y4mPath);
  console.log('Media Info:', JSON.stringify(mediaInfo, null, 2));
  console.log(`  Format: ${mediaInfo.format.name} (${mediaInfo.format.longName})`);
  console.log(`  Duration: ${mediaInfo.format.duration?.toFixed(2) || 'N/A'}s`);
  console.log(`  Bitrate: ${mediaInfo.format.bitRate || 'N/A'} bps`);
  console.log(`  Streams: ${mediaInfo.streams.length}`);
  
  if (mediaInfo.streams.length > 0) {
    const stream = mediaInfo.streams[0];
    console.log(`  Stream 0:`);
    console.log(`    Codec: ${stream.codecName} (${stream.codecType})`);
    console.log(`    Dimensions: ${stream.width || 'N/A'}x${stream.height || 'N/A'}`);
    console.log(`    Frame Rate: ${stream.frameRate || 'N/A'} fps`);
  }
} catch (error) {
  console.error('Error getting media info:', error);
}

// ============================================================================
// Example 3: Format Transformation
// ============================================================================

console.log('\n=== Example 3: Format Transformation ===\n');

// Transform Y4M to Matroska (WebM)
const webmPath = path.join(__dirname, 'test_files', 'test_video.webm');
try {
  transformFormat(y4mPath, webmPath);
  console.log(`Transformed ${y4mPath} to ${webmPath}`);
  
  // Verify the output file was created
  if (fs.existsSync(webmPath)) {
    const stats = fs.statSync(webmPath);
    console.log(`  Output file size: ${stats.size} bytes`);
    
    // Validate the output file
    const validationResult = validateFile(webmPath);
    console.log(`  Validation: ${validationResult.isValid ? '✓ VALID' : '✗ INVALID'}`);
    if (!validationResult.isValid) {
      console.log(`  Errors: ${validationResult.errors.join(', ')}`);
    }
    if (validationResult.warnings.length > 0) {
      console.log(`  Warnings: ${validationResult.warnings.join(', ')}`);
    }
  }
} catch (error) {
  console.error('Error transforming format:', error);
}

// ============================================================================
// Example 4: Advanced Transcoding with Options
// ============================================================================

console.log('\n=== Example 4: Advanced Transcoding with Options ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath2 = getTestVideo('sample_640x360.y4m');

// Transcode with codec options
const matroskaPath = path.join(__dirname, 'test_files', 'test_video.mkv');
try {
  transcode({
    inputPath: y4mPath2,
    outputPath: matroskaPath,
    videoCodec: {
      codecName: 'av1',
      width: 640,
      height: 480,
      frameRate: 30.0,
      bitRate: 1000000,
    },
    audioCodec: undefined,
    videoFilter: undefined,
    audioFilter: undefined,
    format: 'matroska',
    startTime: undefined,
    duration: undefined,
    seekTo: undefined,
  });
  console.log(`Transcoded ${y4mPath2} to ${matroskaPath} with codec options`);
  
  // Verify the output file was created
  if (fs.existsSync(matroskaPath)) {
    const stats = fs.statSync(matroskaPath);
    console.log(`  Output file size: ${stats.size} bytes`);
    
    // Validate the output file
    const validationResult = validateFile(matroskaPath);
    console.log(`  Validation: ${validationResult.isValid ? '✓ VALID' : '✗ INVALID'}`);
    if (!validationResult.isValid) {
      console.log(`  Errors: ${validationResult.errors.join(', ')}`);
    }
    if (validationResult.warnings.length > 0) {
      console.log(`  Warnings: ${validationResult.warnings.join(', ')}`);
    }
  }
} catch (error) {
  console.error('Error transcoding:', error);
}

// ============================================================================
// Example 5: Transcoding with Video Filters
// ============================================================================

console.log('\n=== Example 5: Transcoding with Video Filters ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath3 = getTestVideo('sample_320x240.y4m');

// Transcode with scale filter
const filteredPath = path.join(__dirname, 'test_files', 'test_video_scaled.mkv');
try {
  transcode({
    inputPath: y4mPath3,
    outputPath: filteredPath,
    videoCodec: undefined,
    audioCodec: undefined,
    videoFilter: {
      filterString: 'scale=640:480',
    },
    audioFilter: undefined,
    format: undefined,
    startTime: undefined,
    duration: undefined,
    seekTo: undefined,
  });
  console.log(`Transcoded ${y4mPath3} to ${filteredPath} with scale filter`);
  
  // Verify the output file was created
  if (fs.existsSync(filteredPath)) {
    const stats = fs.statSync(filteredPath);
    console.log(`  Output file size: ${stats.size} bytes`);
  }
} catch (error) {
  console.error('Error transcoding with filter:', error);
}

// ============================================================================
// Example 6: Extract First 30 Frames
// ============================================================================

console.log('\n=== Example 6: Extract First 30 Frames ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath4 = getTestVideo('sample_320x240.y4m');

// Get media info to determine frame rate
let frameRate = 30.0;
try {
  const mediaInfo = getMediaInfo(y4mPath4);
  if (mediaInfo.streams.length > 0 && mediaInfo.streams[0].frameRate) {
    frameRate = mediaInfo.streams[0].frameRate;
  }
} catch (error) {
  console.log('Could not get frame rate, using default 30 fps');
}

// Calculate duration for 30 frames
const framesToExtract = 30;
const durationSeconds = framesToExtract / frameRate;

console.log(`Extracting first ${framesToExtract} frames from video`);
console.log(`Frame rate: ${frameRate} fps`);
console.log(`Duration: ${durationSeconds.toFixed(3)} seconds\n`);

// Extract first 30 frames using duration parameter
const extractedPath = path.join(__dirname, 'test_files', 'test_video_30frames.mkv');
try {
  transcode({
    inputPath: y4mPath4,
    outputPath: extractedPath,
    videoCodec: undefined,
    audioCodec: undefined,
    videoFilter: undefined,
    audioFilter: undefined,
    format: undefined,
    startTime: undefined,
    duration: durationSeconds, // Extract only first 30 frames
    seekTo: undefined,
  });
  console.log(`Extracted first ${framesToExtract} frames to ${extractedPath}`);
  
  // Verify the output file was created
  if (fs.existsSync(extractedPath)) {
    const stats = fs.statSync(extractedPath);
    console.log(`  Output file size: ${stats.size} bytes`);
    
    // Verify the extracted video info
    const extractedInfo = getMediaInfo(extractedPath);
    console.log(`  Extracted duration: ${extractedInfo.format.duration?.toFixed(3)}s`);
    console.log(`  Expected duration: ${durationSeconds.toFixed(3)}s`);
    
    // Calculate approximate number of frames
    const extractedFrames = extractedInfo.format.duration
      ? Math.round(extractedInfo.format.duration * frameRate)
      : 0;
    console.log(`  Approximate frames: ${extractedFrames}`);
  }
} catch (error) {
  console.error('Error extracting frames:', error);
}

// ============================================================================
// Example 7: Extract Frames as RGBA Buffers
// ============================================================================

console.log('\n=== Example 7: Extract Frames as RGBA Buffers ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath5 = getTestVideo('sample_320x240.y4m');

// Extract first 10 frames as RGBA buffers
try {
  const frames = extractFramesAsRgba(y4mPath5, 10);
  console.log(`Extracted ${frames.length} frames as RGBA buffers`);
  
  if (frames.length > 0) {
    const firstFrame = frames[0];
    console.log(`  First frame:`);
    console.log(`    Frame number: ${firstFrame.frameNumber}`);
    console.log(`    Dimensions: ${firstFrame.width}x${firstFrame.height}`);
    console.log(`    RGBA buffer size: ${firstFrame.rgbaData.length} bytes`);
  }
} catch (error) {
  console.error('Error extracting frames as RGBA:', error);
}

// ============================================================================
// Example 8: Save Frames as Images
// ============================================================================

console.log('\n=== Example 8: Save Frames as Images ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath6 = getTestVideo('sample_320x240.y4m');

// Extract frames and save as PNG images
const outputDir = path.join(__dirname, 'test_files', 'extracted_frames');
try {
  const frames = extractFramesAsRgba(y4mPath6, 10);
  console.log(`Extracted ${frames.length} frames`);
  
  const savedPaths = saveFramesAsImages(frames, {
    outputDir: outputDir,
    imageFormat: 'png',
    filenamePrefix: 'frame',
    frameNumberDigits: 4,
  });
  
  console.log(`Saved ${savedPaths.length} frames as PNG images`);
  console.log(`  Output directory: ${outputDir}`);
  console.log(`  First saved frame: ${savedPaths[0]}`);
  console.log(`  Last saved frame: ${savedPaths[savedPaths.length - 1]}`);
} catch (error) {
  console.error('Error saving frames as images:', error);
}

// ============================================================================
// Example 9: Extract Frames Directly to Images
// ============================================================================

console.log('\n=== Example 9: Extract Frames Directly to Images ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath7 = getTestVideo('sample_640x360.y4m');

// Extract frames and save directly as JPEG images
const outputDir2 = path.join(__dirname, 'test_files', 'extracted_frames_jpg');
try {
  const savedPaths = extractFramesToImages(
    y4mPath7,
    outputDir2,
    10, // Extract first 10 frames
    'jpg'
  );
  
  console.log(`Extracted and saved ${savedPaths.length} frames as JPEG images`);
  console.log(`  Output directory: ${outputDir2}`);
  console.log(`  First saved frame: ${savedPaths[0]}`);
  console.log(`  Last saved frame: ${savedPaths[savedPaths.length - 1]}`);
} catch (error) {
  console.error('Error extracting frames to images:', error);
}

// ============================================================================
// Example 10: Extract Frames Using v_frame
// ============================================================================

console.log('\n=== Example 10: Extract Frames Using v_frame ===\n');

// Get Y4M video generated by FFmpeg
const y4mPath8 = getTestVideo('sample_320x240.y4m');

// Extract frames using v_frame library
try {
  const frames = extractFramesWithVFrame(y4mPath8, 10);
  console.log(`Extracted ${frames.length} frames using v_frame`);
  
  if (frames.length > 0) {
    const firstFrame = frames[0];
    console.log(`  First frame:`);
    console.log(`    Frame number: ${firstFrame.frameNumber}`);
    console.log(`    Dimensions: ${firstFrame.width}x${firstFrame.height}`);
    console.log(`    RGBA buffer size: ${firstFrame.rgbaData.length} bytes`);
  }
} catch (error) {
  console.error('Error extracting frames with v_frame:', error);
}

// ============================================================================
// Example 11: Error Handling
// ============================================================================

console.log('\n=== Example 6: Error Handling ===\n');

// Try to get media info from non-existent file
try {
  getMediaInfo('/non/existent/file.mp4');
  console.log('This should not print');
} catch (error) {
  console.log('Expected error caught:', (error as Error).message);
}

// Try to transform non-existent file
try {
  transformFormat('/non/existent/input.y4m', '/non/existent/output.mkv');
  console.log('This should not print');
} catch (error) {
  console.log('Expected error caught:', (error as Error).message);
}

// ============================================================================
// Cleanup
// ============================================================================

console.log('\n=== Cleanup ===\n');
console.log('Note: Generated test videos are preserved for reuse.');
console.log('Run "bun run videos:clean" to remove all test videos if needed.');

console.log('\n=== Examples Complete ===\n');
console.log('All examples have been executed successfully.');
console.log('Check the test_files directory for generated output files.');
